{
  "environment": "web",
  "format": "html",
  "prefix": "https://storage.googleapis.com",
  "mainga": "UA-49880327-14",
  "updated": "2020-09-13T12:37:17Z",
  "id": "batch_ingestion_datafusion",
  "duration": 24,
  "title": "Lab \"Batch Ingestion: Cloud Data Fusion\"",
  "authors": "Peer KÃ¼ppers",
  "summary": "XXX In this codelab, you'll set up a sqoop job from o a DataProc cluster that retrieves a table from a cloud SQL instance and stores the data in the data lake (HDFS/GCS) in the popular big data file formats \"Avro\" and \"Parquet\".",
  "source": "1ny2NVO-eH0pzHVIgc6LAvHU0JWeCx_RWDVQ6QPlbL_g",
  "theme": "batch-ingestion",
  "status": [
    "published"
  ],
  "category": [
    "Batch Ingestion"
  ],
  "tags": [
    "pk"
  ],
  "feedback": "https://p-kueppers.com",
  "ga": "None",
  "url": "batch_ingestion_datafusion"
}
