
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Lab &#34;Batch Ingestion: Image to GCS with Cloud Functions&#34;</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/claat-public/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid="None"
                  id="batch_ingestion_cloudfunctionimage"
                  title="Lab &#34;Batch Ingestion: Image to GCS with Cloud Functions&#34;"
                  environment="web"
                  feedback-link="https://p-kueppers.com">
    
      <google-codelab-step label="Introduction" duration="0">
        <p>In this use case we want to store the regularly updated image of a webcam in our data lake (based on GCS) in order to, e.g., let a machine learning algorithm identify whether it&#39;s cloudy or not. We want to achieve this task in a scalable manner, i.e. be able to add potentially thousands of webcams and still be able to guarantee performance. See and check the webcam.</p>
<p class="image-container"><img style="width: 624.00px" src="img\\fb27a11a4a492891.png"></p>
<h3 is-upgraded><strong>Goal</strong></h3>
<p>Ingesting unstructured image data into the data lake for batch processing via a (vertically) scalable cloud function.</p>
<h2 is-upgraded><strong>What you&#39;ll implement</strong></h2>
<ul>
<li>Take a look at the Python logic to download images via http in Python in a cloud Jupyter notebook.</li>
<li>Transfer the Python logic from a local machine to the cloud function.</li>
<li>Schedule the cloud function for regular execution.</li>
</ul>
<aside class="warning"><p><strong>Please note:</strong> You&#39;ll need GCP access for this lab. The provided voucher needs to be redeemed. Remember to shut down the running cloud function after completing!</p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Downloading images in Python (example in a notebook)" duration="5">
        <h2 is-upgraded><strong>Creating a cloud-based Jupyter Notebook environment</strong></h2>
<p>If you don&#39;t have Anaconda and Jupyter Notebook installed        locally on your computer, please create a notebook in GCP&#39;s AI Platform using Vertex AI / Colab Enterprise:</p>
<p class="image-container"><img style="width: 239.00px" src="img\\487dbf8b21fdf691.png"></p>
<h2 is-upgraded><strong>Creating the Notebook and Implementing the Logic</strong></h2>
<p>Create a Python 3 notebook and and insert the following imports into the first cell:</p>
<pre><code>import requests  # will be used to retrieve the image via http / a URL
from IPython.display import Image  # will be used to show one exemplary image in the notebook
from datetime import datetime  # will be used to format the filename</code></pre>
<p>Show the current image of this webcam using the following code in another cell:</p>
<pre><code>url = &#39;https://www.kite-connection.at/weatherstation/webcam/rohrspitz.jpg&#39; # image url
Image(url=url, width=300)  # show image in notebook</code></pre>
<p>Now, let&#39;s download the current image to the local disk (of our JupyterLab machine):</p>
<pre><code>filename = f&#34;webcam_{datetime.now().strftime(&#39;%Y%m%d_%H%M%S&#39;)}.png&#34;
response = requests.get(url)
file = open(filename, &#34;wb&#34;)
file.write(response.content)
file.close()</code></pre>
<p>When updating the file browser you should see the image (which you can open in JuypterLab):</p>
<p class="image-container"><img style="width: 624.00px" src="img\\e8a2c5943a793c5f.png"></p>
<h2 is-upgraded><strong>Upload image to GCS (only in cloud JupyterLab possible)</strong></h2>
<p>In case you are working in the cloud JupyterLab, you can access the cloud storage easily with the following code:</p>
<pre><code>from google.cloud import storage
storage_client = storage.Client()
bucket = storage_client.get_bucket(&#34;hdm-kueppers&#34;)
blob = bucket.blob(filename)
blob.upload_from_string(response.content, content_type=&#39;image/png&#39;)</code></pre>
<p>You should now be able to see this image in the cloud console (under Cloud Storage)</p>
<p class="image-container"><img style="width: 624.00px" src="img\\f12278d10eda33b.png"></p>
<p>The notebook could now be executed, e.g. hourly, in order to create a history of webcam images. However, the notebook is only used for demo purposes and we now want to see how one can deploy such an ingestion logic to a cloud function.</p>
<h2 is-upgraded><strong>Results</strong></h2>
<ol type="1" start="1">
<li>You created a Jupyter Notebook in order to understand the requirements of our ingestion logic: pulling an image via http to the data lake.</li>
<li>You set up a Notebook environment in the cloud which is capable of accessing different resources in your GCP project, especially cloud storage.</li>
<li>You pulled a sample image from the webcam and (1) showed it in the notebook, (2) stored it locally on the JupyterLab virtual machine, and (3) stored it on GCS, i.e. the data lake.</li>
<li>Next, we want to transfer the logic to a cloud function.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Creating and Developing the Cloud Function" duration="9">
        <h2 is-upgraded><strong>Creating a cloud function for image retrieval and storage upload</strong></h2>
<p>Please go to cloud functions in the console:</p>
<p class="image-container"><img style="width: 270.00px" src="img\\1b888a627ffe6857.png"></p>
<p>Create a function:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\d21990bcaa67de4a.png"></p>
<p>We&#39;ll use the inline editor:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\39d7ecef3f72796d.png"></p>
<p>Set the function (=service) name to &#34;image-ingestion-yourintials&#34;. Choose us-central1 as region and a modern Python runtime. Set &#34;Allow public access&#34; under &#34;Authentication&#34;. The other parameters can be set as default. Hit create:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\2c0d4027221af5f4.png"></p>
<aside class="special"><p><strong>Please note:</strong> In the &#34;Containers, Volumes, Networking, Security section you are able to set the allocated memory for the cloud function (in case you have larger requirements than 256 MB).</p>
</aside>
<h2 is-upgraded><strong>Developing the cloud function</strong></h2>
<p>You are working in the file &#34;main.py&#34;. This file holds the logic we want to deploy to our cloud function. Let&#39;s transfer the logic of the Jupyter Notebook to our method &#34;ingest_image&#34;:</p>
<pre><code>import functions_framework
import requests
from datetime import datetime
from google.cloud import storage

@functions_framework.http
def ingest_image(request):
    &#34;&#34;&#34;Pull an image from the webcam and store it in GCS &#34;&#34;&#34;
    # pull the image
    url = &#39;https://www.kite-connection.at/weatherstation/webcam/rohrspitz.jpg&#39;
    filename = f&#34;webcam_fromfunction_{datetime.now().strftime(&#39;%Y%m%d_%H%M%S&#39;)}.png&#34;  # add a timestamp
    response = requests.get(url)

    # store it in GCS
    storage_client = storage.Client()
    bucket = storage_client.get_bucket(&#34;hdm-kueppers&#34;)  # replace the bucket name with yours
    blob = bucket.blob(filename)
    blob.upload_from_string(response.content, content_type=&#39;image/png&#39;)

    return &#39;Success&#39;
</code></pre>
<p>Next, we&#39;ll need to specify that our cloud function requires some Python packages. Click on &#34;requirements.txt&#34; and add this code at the end of the file:</p>
<pre><code>functions-framework==3.*
google-cloud-storage
requests
datetime</code></pre>
<p>Your UI should now look like this:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\f7dbfc4af3a6eef.png"></p>
<p>Please rename the function entry point to &#34;ingest_image&#34; and save + redeploy:</p>
<p class="image-container"><img style="width: 416.00px" src="img\\9c7f0fc40b477151.png"></p>
<p>Wait 1-2 minutes until the final function is deployed and then click on the URL:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\21dd3102cbdfdaa8.png"></p>
<p>The output should be &#34;Succes&#34; and you should now see the output file in your bucket:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\a633fdd9491ddb42.png"></p>
<h2 is-upgraded><strong>Results</strong></h2>
<ol type="1" start="1">
<li>You transferred the sample logic from the notebook to a cloud function (main.py).</li>
<li>You specified requirements on packages of your function (requirements.txt).</li>
<li>You deployed the function and tested it.</li>
<li>The ingestion logic (i.e. the cloud function) is now ready to be scheduled regularly.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Scheduling the Cloud Function" duration="6">
        <h2 is-upgraded><strong>Scheduling cloud function calls </strong></h2>
<p>Please navigate to the cloud scheduler (under &#34;Tools&#34;) and create a job:</p>
<p class="image-container"><img style="width: 482.00px" src="img\\ee09068d1c828b96.png"></p>
<p>The job could be called &#34;scheduled_webcam_ingest&#34; and let&#39;s set the frequency to once per minute (* * * * *). In &#34;Timezone&#34; you can search for &#34;Central European&#34;.</p>
<p class="image-container"><img style="width: 556.00px" src="img\\63ab10f2e74e659e.png"></p>
<p>Hit continue and select HTTP as target. Paste the URL of your cloud function there:</p>
<p class="image-container"><img style="width: 555.00px" src="img\\bf320e4bf958a868.png"></p>
<p>You should see the result in your GCS bucket. Now, every minute a further image should be added to the bucket:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\395f64d3ef54549e.png"></p>
<h2 is-upgraded><strong>Results</strong></h2>
<ol type="1" start="1">
<li>You now scheduled your cloud function regularly. </li>
<li>You set up a whole ingestion pipeline using cloud functions and cloud storage as a data lake. This setup is now an &#34;operation-ready&#34; architecture and could be used in productive environments.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Cleaning Up" duration="2">
        <p>Please make sure to delete your scheduled job in the cloud scheduler:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\b8a5636659fd5994.png"></p>
<p>Next, you may want to delete the files in the bucket:</p>
<p class="image-container"><img style="width: 624.00px" src="img\\4ee74dabb51d1ef4.png"></p>
<p>Next, you should delete the cloud function by selecting it and hitting delete.</p>
<h2 is-upgraded><strong>Results</strong></h2>
<ol type="1" start="1">
<li>You finished the lab and performed all necessary clean-up tasks.</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Congratulations" duration="2">
        <p>Congratulations, you set up a state-of-the-art cloud ingestion pipeline using cloud functions and scheduled its execution.</p>
<aside class="warning"><p><strong>Warning: </strong>The logic of one cloud function is not &#34;auto-scaling&#34; by itself. Thus, if you want to scale out (e.g. to 10000 webcams), you might first need to scale vertically (provide the function more RAM) and then horizontally in a manual manner (e.g. by generating 100 cloud functions, each being responsible for the ingestion of 100 webcam images).</p>
</aside>
<aside class="special"><p><strong>Hint: </strong>in order to avoid high costs for the notebook instance you should first develop in a local environment (e.g. using Anaconda) and then deploy to a cloud notebook or cloud function. However, accessing resources from outside the project (e.g. a notebook in GCP) is more complex. We will get to know how this works later (service accounts are necessary).</p>
</aside>
<aside class="special"><p><strong>Please note: </strong>You can now close this lab.</p>
</aside>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/claat-public/native-shim.js"></script>
  <script src="https://storage.googleapis.com/claat-public/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/claat-public/prettify.js"></script>
  <script src="https://storage.googleapis.com/claat-public/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
